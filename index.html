
<!DOCTYPE html>
<html lang="en">
  <head>	  
    <!-- Global Site Tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-107224691-1"></script>
    <script>
       window.dataLayer = window.dataLayer || [];
       function gtag(){dataLayer.push(arguments)};
       gtag('js', new Date());

       gtag('config', 'UA-107224691-1');
    </script>

    <title>Jack Parker-Holder</title>
	  
    <!-- Credit to Reid Pryzant from Stanford for the website design... I largely plagiarized his work! -->

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
    <script type="text/javascript" src="https://use.fontawesome.com/981e0eb420.js"></script>
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link href='https://fonts.googleapis.com/css?family=Lato:300,400,700,900%7COpen+Sans:400,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="./static/style.css" />

    <link rel="shortcut icon" href="./img/favicon.ico" >
</head>


<body>
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
    	      <img src="img/jack+doris.png" alt="JPH :)" class="headshot">
    	      <br/>
                    <h1>Jack Parker-Holder
                        <small>
                            <a>jparkerholder@gmail.com </a> <span class="sep">|</span>
                            <span style="display: inline-block; white-space: nowrap;">
                                <a href="http://github.com/jparkerholder"><i class="fa fa-git"></i></a> <span class="sep">|</span>
                                <a href="https://www.linkedin.com/in/jack-parker-holder-0bb66a29"><i class="fa fa-linkedin-square"></i></a>
                            </span>
                        </small>
                    </h1>
            </div>
        </div>
        <hr/>
        <div class="row">
            <div class="col-sm-2"><h5>About</h5></div>
            <div class="col-sm-10">
I am a Research Scientist at Google DeepMind in the Open-Endedness Team and an Honorary Lecturer at University College London, where I am part of <a href="https://ucldark.com/" target="_blank" rel="nofollow">UCL DARK</a>. I am interested in building open-ended systems that are worth running forever. For an example of my recent work, see <a href="https://arxiv.org/abs/2301.07608" target="_blank" rel="nofollow">AdA</a>.

</br></br>
Before joining Google DeepMind was a DPhil student at St Peter's College, Oxford, where I was part of the <a href="http://www.robots.ox.ac.uk/~parg/" target="_blank" rel="nofollow">Machine Learning Research Group</a>, advised by <a href="https://www.robots.ox.ac.uk/~sjrob/" target="_blank" rel="nofollow">Stephen Roberts</a>. I also completed internships at FAIR London with Tim Rocktäschel and Ed Grefenstette and Aspect Capital in the ML group. In a previous life I had a seven year finance career, as both a Quantitative Researcher and ETF Trader at J.P. Morgan in New York. While in America I studied for a Master's part-time at Columbia where I discovered the joys of machine learning research! I am originally from the UK, and studied Maths at Exeter. 
</br></br>

Aside from AI research, I also enjoy parenting a daughter and a dog, travel, Brazilian Jiu Jitsu and supporting Chelsea FC. 

</br></br>

        </div>
        </div>
        <hr/>

        <div class="row">
            <div class="col-sm-2">
                <h5>News</h5>
            </div>
            <div class="col-sm-10">
          

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-12 columns">
                                <ul>
                                <li><b>[10/2023] </b> I have joined UCL as an Honorary Lecturer in Computer Science :)
                                </li>
                                </br> 
                                <li><b>[9/2023] </b> Two papers accepted to NeurIPS 2023, back to New Orleans again!
                                </li>
                                </br> 
                                <li><b>[7/2023] </b> The Agent Learning in Open-Endedness workshop is back for version 2 at NeurIPS 2023!
                                </li>
                                </br> 
                                <li><b>[6/2023] </b> AdA was accepted as an Oral at ICML 2023!
                                </li>
                                </br>  
                                <li><b>[1/2023] </b> Our work on AdA was covered in the New Scientist (<a href="https://www.newscientist.com/article/2357017-deepmind-ai-is-as-fast-as-humans-at-solving-previously-unseen-tasks/" target="_blank" rel="nofollow">here</a>).
                                </li>
                                </br>  
                                <li><b>[1/2023] </b> One paper accepted to ICLR 2023!
                                </li>
                                </br>                         
                                <li><b>[9/2022] </b> Two papers accepted to NeurIPS 2022, looking forward to NOLA! 
                                </li>
                                </br> 
                                <li><b>[7/2022] </b> I have joined DeepMind as a Research Scientist in the Open-Endedness team :) 
                                </li>
                                </br> 
                                <li><b>[6/2022] </b> Our new work on <a href="https://arxiv.org/abs/2206.04779" target="_blank" rel="nofollow">offline RL from pixels</a> won an Outstanding Paper Award at <a href="https://sites.google.com/view/l-dod-rss2022" target="_blank" rel="nofollow">L-DOD</a>. 
                                </li>
                                </br> 
                                <li><b>[5/2022] </b> Two papers accepted to ICML 2022... see you in Baltimore :) 
                                </li>
                                </br> 
                                <li><b>[4/2022] </b> We are organizing the first workshop on Agent Learning in Open-Endedness at ICLR 2022, <a href="https://sites.google.com/view/aloe2022" target="_blank" rel="nofollow">come along</a>! 
                                </li>
                                </br> 
                                <li><b>[3/2022] </b> New work on multi-task RL was given an <a href="http://aistats.org/aistats2022/awards.html" target="_blank" rel="nofollow">honorable mention</a> for best paper at AISTATS!
                                </li>
                                </br> 
                                <li><b>[3/2022] </b> We released ACCEL, a new algorithm for open-ended learning, <a href="https://accelagent.github.io/" target="_blank" rel="nofollow">check it out</a>! 
                                </li>
                                </br> 
                                <li><b>[9/2021] </b> Three papers accepted to NeurIPS 2021! I'm grateful to work with such great people :) 
                                </li>
                                </br> 
                                <li><b>[6/2021]</b> I am interning at Facebook AI Research with Tim Rocktäschel and Ed Grefenstette. 
                                </li>
                                </br> 
                                <li><b>[11/2020]</b> PB2 was included into Ray Tune! Check out the <a href="https://www.anyscale.com/blog/population-based-bandits" target="_blank" rel="nofollow">blog post</a>. 
                                </li>
                                </br> 
                                <li><b>[9/2020]</b> Three papers accepted to NeurIPS 2020. Thank you to my amazing collaborators!! 
                                </li>
                                </br>  
                                <li><b>[6/2020]</b> Three papers accepted to the main conference at ICML 2020.
                                </li>
                                </li>
                                </br>                                  
                                <li><b>[2/2020]</b> New work on model-based RL, <i> Ready Policy One</i>, was covered by VentureBeat (<a href="https://venturebeat.com/2020/02/11/researchers-develop-technique-to-increase-sample-efficiency-in-reinforcement-learning/" target="_blank" rel="nofollow">here</a>). </li>
                                </ul>
                            </div>
                        </td>
                    </tr>
                </table> 
   
            </div>
            </div>
        <hr/>

        <div class="row">
            <div class="col-sm-2">
                <h5>Conference Papers</h5>
            </div>
            <div class="col-sm-10">

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/synther.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Synthetic experience replay</b>  </br> 
                                Cong Lu*, Philip J. Ball*, Yee Whye Teh, <b>Jack Parker-Holder</b> </br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2023 </i> </br>
                                (<a href="https://arxiv.org/abs/2303.06614" target="_blank" rel="nofollow">Paper</a>) (<a href="https://github.com/conglu1997/SynthER" target="_blank" rel="nofollow">Code</a>) 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/groove.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Discovering General Reinforcement Learning Algorithms with Adversarial Environment Design</b>  </br> 
                                Matthew T. Jackson, Minqi Jiang, <b>Jack Parker-Holder</b> , Risto Vuorio, Chris Lu, Gregory Farquhar, Shimon Whiteson, Jakob Foerster</br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2023 </i> </br>
                                (<a href="https://arxiv.org/abs/2310.02782" target="_blank" rel="nofollow">Paper</a>) (<a href="https://github.com/EmptyJackson/groove" target="_blank" rel="nofollow">Code</a>) 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/ada.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Human-Timescale Adaptation in an Open-Ended Task Space</b>  </br> 
                                Adaptive Agent Team, Jakob Bauer, Kate Baumli, Satinder Baveja, Feryal Behbahani, Avishkar Bhoopchand, Nathalie Bradley-Schmieg, Michael Chang, Natalie Clay, Adrian Collister, Vibhavari Dasagi, Lucy Gonzalez, Karol Gregor, Edward Hughes, Sheleem Kashem, Maria Loks-Thompson, Hannah Openshaw, <b>Jack Parker-Holder</b>, Shreya Pathak, Nicolas Perez-Nieves, Nemanja Rakicevic, Tim Rocktäschel, Yannick Schroecker, Jakub Sygnowski, Karl Tuyls, Sarah York, Alexander Zacherl, Lei Zhang </br> 
                                <i>The International Conference on Machine Learnning (ICML), 2023 </i> <font color=#189441><strong>(Oral)</strong></font>  </br>
                                (<a href="https://arxiv.org/abs/2301.07608" target="_blank" rel="nofollow">Paper</a>) (<a href="https://sites.google.com/view/adaptive-agent/" target="_blank" rel="nofollow">Website</a>) (<a href="https://www.newscientist.com/article/2357017-deepmind-ai-is-as-fast-as-humans-at-solving-previously-unseen-tasks/" target="_blank" rel="nofollow">New Scientist</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/maestro.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>MAESTRO: Open-ended environment design for multi-agent reinforcement learning</b>  </br> 
                                Mikayel Samvelyan, Akbir Khan, Michael Dennis, Minqi Jiang, <b>Jack Parker-Holder</b>, Jakob Foerster, Roberta Raileanu, Tim Rocktäschel </br> 
                                <i>The International Conference on Learning Representations (ICLR), 2023 </i> </br>
                                (<a href="https://arxiv.org/abs/2303.03376" target="_blank" rel="nofollow">Paper</a>) (<a href="https://sites.google.com/view/maestro-ued" target="_blank" rel="nofollow">Website</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/cascade.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Learning Genneral World Models in a Handful of Reward Free Deployments </b>  </br> 
                                Yingchen Xu*, <b>Jack Parker-Holder*</b>, Aldo Pacchiano*, Philip J. Ball*, Oleh Rybkin, Stephen J. Roberts, Tim Rocktäschel, Edward Grefenstette </br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2022 </i> </br>
                                (<a href="https://arxiv.org/abs/2210.12719" target="_blank" rel="nofollow">Paper</a>) (<a href="https://yingchenxu.com/cascade/" target="_blank" rel="nofollow">Website</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/accel.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Evolving Curricula with Regret-Based Environment Design </b>  </br> 
                                <b>Jack Parker-Holder*</b>, Minqi Jiang*, Michael Dennis, Mikayel Samvelyan, Jakob Foerster, Edward Grefenstette, Tim Rocktäschel </br> 
                                <i>The International Conference on Machine Learning (ICML), 2022 </i> </br>
                                (<a href="https://arxiv.org/abs/2203.01302" target="_blank" rel="nofollow">Paper</a>) (<a href="https://accelagent.github.io/" target="_blank" rel="nofollow">Website</a>) (<a href="https://www.youtube.com/watch?v=povBDxUn1VQ" target="_blank" rel="nofollow">Paper Review</a>) (<a href="https://www.youtube.com/watch?v=16BsJI5I-Yw&t=151s" target="_blank" rel="nofollow">Video Interview</a>) 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/gkat.png" width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>From block-Toeplitz matrices to differential equations on graphs: towards a general theory for scalable masked Transformers</b>  </br> 
                                Krzysztof Choromanski*, Han Lin*, Haoxian Chen*, Tianyi Zhang, Arijit Sehanobish, Valerii Likhosherstov, <b>Jack Parker-Holder</b>, Tamas Sarlos, Adrian Weller, Thomas Weingarten </br> 
                                <i>The International Conference on Machine Learning (ICML), 2022 </i> </br>
                                (<a href="https://arxiv.org/abs/2107.07999" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/revisiting.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Revisiting Design Choices in Offline Model Based Reinforcement Learning  </b>  </br> 
                                Cong Lu*, Philip Ball*, <b>Jack Parker-Holder</b>, Michael Osborne, Stephen Roberts  </br> 
                                <i>International Conference on Learning Representations (ICLR), 2022 </i> <font color=#189441><strong>(Spotlight)</strong></font>  </br>
                                <i>Reinforcement Learning for Real Life Workshop @ ICML, 2021 </i> <font color=#189441><strong>(Spotlight)</strong></font>  </br>
                                (<a href="https://drive.google.com/file/d/1qQDeG-nQ5-XqARssY3X2YAAFwp8_n2Nq/view" target="_blank" rel="nofollow">Paper</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  


                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/texus.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Towards an Understanding of Default Policies in Multitask Policy Optimization </b>  </br> 
                                Ted Moskovitz, Michael Arbel, <b>Jack Parker-Holder</b>, Aldo Pacchiano</br> 
                                <i>Artificial Intelligence and Statistics (AISTATS), 2022 </i> <font color=#189441><strong>(Oral, Best Paper Honorable Mention)</strong></font>  </br>
                                (<a href="https://arxiv.org/abs/2111.02994" target="_blank" rel="nofollow">Paper</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/osa.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>On-the-fly Strategy Adaptation for ad-hoc Agent Coordination  </b>  </br> 
                                Jaleh Zand, <b>Jack Parker-Holder</b>, Stephen Roberts  </br> 
                                <i>International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), 2022 </i> </br>
                                <i>Cooperative AI Workshop, NeurIPS, 2021 </i> </br>
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/grr.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Lyapunov Exponents for Diversity in Differentiable Games</b>  </br> 
                                Jonathan Lorraine, Paul Vicol, <b>Jack Parker-Holder</b>, Tal Kachman, Luke Metz, Jakob Foerster </br> 
                                <i>International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), 2022 </i> </br>
                                <i>Beyond first-order methods in ML systems workshop, ICML, 2021 </i> </br>
                                (<a href="https://arxiv.org/abs/2112.14570" target="_blank" rel="nofollow">Paper</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/unclear.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Same State, Different Task: Continual Reinforcement Learning without Interference </b>  </br> 
                                Samuel Kessler, <b> Jack Parker-Holder</b>, Philip Ball, Stefan Zohren, Stephen Roberts </br> 
                                <i>AAAI Conference on Artificial Intelligence, 2022 </i>  </br>
                                <i>Workshop on Continual Learning, ICML, 2020 </i>  </br>
                                (<a href="https://arxiv.org/abs/2106.02940" target="_blank" rel="nofollow">Paper</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/pb2m.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Tuning Mixed Input Hyperparameters on the Fly for Efficient Population Based AutoRL </b>  </br> 
                                 <b>Jack Parker-Holder</b>, Vu Nguyen, Shaan Desai, Stephen Roberts </br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2021 </i>  </br>                                  
                                (<a href="https://arxiv.org/abs/2106.15883" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/silverstone.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Replay-Guided Adversarial Environment Design </b>  </br> 
                                 Minqi Jiang*, Michael Dennis*, <b>Jack Parker-Holder</b>, Jakob Foerster, Edward Grefenstette, Tim Rocktäschel </br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2021 </i>  </br>     
                                (<a href="https://arxiv.org/abs/2110.02439" target="_blank" rel="nofollow">ArXiv</a>)                             
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/dope.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Tactical Optimism and Pessimism for Deep Reinforcement Learning  </b>  </br> 
                                Ted Moskovitz, <b> Jack Parker-Holder</b>, Aldo Pacchiano, Michael Arbel, Michael I. Jordan </br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2021 </i>  </br> 
                                (<a href="https://arxiv.org/abs/2102.03765" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 


                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/minihack.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> MiniHack the Planet: A Sandbox for Open-Ended Reinforcement Learning Research </b>  </br> 
                                Mikayel Samvelyan, Robert Kirk, Vitaly Kurin, <b> Jack Parker-Holder</b>, Minqi Jiang, Eric Hambro, Fabio Petroni, Heinrich Kuttler, Edward Grefenstette, Tim Rocktäschel  </br> 
                                <i>NeurIPS (Datasets and Benchmarks Track), 2021 </i> </br>
                                (<a href="https://openreview.net/forum?id=skFwlyefkWJ" target="_blank" rel="nofollow">Paper</a>)
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/AugWM.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environment </b>  </br> 
                                Philip J Ball*, Cong Lu*, <b> Jack Parker-Holder</b>, Stephen Roberts </br> 
                                <i>The International Conference on Machine Learning (ICML), 2021 </i> </br>
                                <i>Workshop on Self-Supervision in Reinforcement Learning, ICLR, 2021 </i>  <font color=#189441><strong>(Spotlight)</strong></font>  </br>
                                (<a href="https://arxiv.org/pdf/2104.05632.pdf" target="_blank" rel="nofollow">Paper</a>) (<a href="https://sites.google.com/view/augmentedworldmodels/" target="_blank" rel="nofollow">Website</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/narl.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Towards Tractable Optimism in Model-Based Reinforcement Learning </b>  </br> 
                                Aldo Pacchiano*, Philip Ball*, <b> Jack Parker-Holder*</b>, Krzysztof Choromanski, Stephen Roberts </br> 
                                 <i> Uncertainty in Artificial Intelligence (UAI), 2021 </i> </br>
                               (<a href="https://arxiv.org/abs/2006.11911" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/dvd.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Effective Diversity in Population-Based Reinforcement Learning </b>  </br> 
                                <b> Jack Parker-Holder*</b>, Aldo Pacchiano*, Krzysztof Choromanski, Stephen Roberts </br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2020 </i> <font color=#189441><strong>(Spotlight)</strong></font> </br> 
                                <i> The Fourth Lifelong Machine Learning Workshop at ICML, 2020 </i> </br>
                                (<a href="https://arxiv.org/abs/2002.00632" target="_blank" rel="nofollow">ArXiv</a>) (<a href="https://www.youtube.com/watch?v=2k26xxPw3CA" target="_blank" rel="nofollow">Talk</a>) (<a href="https://github.com/jparkerholder/DvD_ES" target="_blank" rel="nofollow">Code</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/p2bt.png" width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Provably Efficient Online Hyperparameter Optimization with Population-Based Bandits </b>  </br> 
                                <b>Jack Parker-Holder</b>, Vu Nguyen, Stephen Roberts </br>                                 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2020 </i>  </br> 
                                <i>The 7th ICML Workshop on Automated Machine Learning (AutoML), 2020  </i> <font color=#189441><strong>(Contributed Talk)</strong></font> </br>
                                (<a href="https://arxiv.org/abs/2002.02518" target="_blank" rel="nofollow">ArXiv</a>) (<a href="https://www.anyscale.com/blog/population-based-bandits" target="_blank" rel="nofollow">Blog</a>) (<a href="https://github.com/jparkerholder/PB2" target="_blank" rel="nofollow">Code</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                <img src="img/pubs/rr.png" width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Ridge Rider: Finding diverse solutions by following eigenvectors of the Hessian </b>  </br> 
                                <b>Jack Parker-Holder*</b>, Luke Metz, Cinjon Resnick, Hengyuan Hu, Adam Lerer, Alistair HP Letcher, Alex Peysakhovich, Aldo Pacchiano, Jakob Foerster* </br>                                 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2020 </i>  </br> 
                                <i>Beyond First Order Methods in ML Systems, ICML, 2020 </i> <font color=#189441><strong>(Spotlight)</strong></font> </br>
                                (<a href="https://arxiv.org/abs/2011.06505?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%253A+arxiv%252FQSXk+%2528ExcitingAds%2521+cs+updates+on+arXiv.org%2529" target="_blank" rel="nofollow">Arxiv</a>) (<a href="https://bair.berkeley.edu/blog/2020/11/13/ridge-rider/" target="_blank" rel="nofollow">Blog</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/rp1.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Ready Policy One: World Building Through Active Learning </b>  </br> 
                                Philip Ball*, <b> Jack Parker-Holder*</b>, Aldo Pacchiano, Krzysztof Choromanski, Stephen Roberts </br> 
                                <i>The International Conference on Machine Learning (ICML), 2020 </i>  </br> 
                                (<a href="https://arxiv.org/pdf/2002.02693" target="_blank" rel="nofollow">ArXiv</a>) (<a href="https://venturebeat.com/2020/02/11/researchers-develop-technique-to-increase-sample-efficiency-in-reinforcement-learning/" target="_blank" rel="nofollow">Media</a>) (<a href="https://github.com/fiorenza2/ReadyPolicyOne" target="_blank" rel="nofollow">Code</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/wass.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Learning to Score Behaviors for Guided Policy Optimization</b>  </br> 
                                Aldo Pacchiano*, <b> Jack Parker-Holder*</b>, Yunhao Tang*, Anna Choromanska, Krzysztof Choromanski, Michael I. Jordan </br> 
                                <i>The International Conference on Machine Learning (ICML), 2020 </i> </br>
                                (<a href="https://arxiv.org/abs/1906.04349" target="_blank" rel="nofollow">ArXiv</a>) (<a href="https://github.com/behaviorguidedRL/BGRL" target="_blank" rel="nofollow">Code</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/ortho.png" width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Stochastic Flows and Geometric Optimization on the Orthogonal Group</b>  </br> 
                                Krzysztof Choromanski*, David Cheikhi*, Jared Davis*, Valerii Likhosherstov*, Achille Nazaret*, Achraf Bahamou*, Xingyou Song*, Mrugank Akarte, <b> Jack Parker-Holder</b>, Jacob Bergquist, Yuan Gao, Aldo Pacchiano, Tamas Sarlos, Adrian Weller, Vikas Sindhwani </br> 
                                <i>The International Conference on Machine Learning (ICML), 2020 </i> </br>
                                (<a href="https://arxiv.org/abs/2003.13563" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 


                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/dppmc.png" width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> </br> Practical Nonisotropic Monte Carlo Sampling in High Dimensions via Determinantal Point Processes </b></br>
                                Krzysztof Choromanski*, Aldo Pacchiano*, <b> Jack Parker-Holder*</b>, Yunhao Tang* </br> 
                                <i>Artificial Intelligence and Statistics (AISTATS), 2020 </i> </br>
                                (<a href="https://arxiv.org/abs/1905.12667" target="_blank" rel="nofollow">ArXiv</a>) 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  	      

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/asebo.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>From Complexity to Simplicity: Adaptive ES-Active Subspaces for Blackbox Optimization</b></br> 
                                Krzysztof Choromanski*, Aldo Pacchiano*, <b> Jack Parker-Holder*</b>, Yunhao Tang*, Vikas Sindhwani</br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2019  </i> </br>
                                (<a href="https://arxiv.org/pdf/1903.04268" target="_blank" rel="nofollow">ArXiv</a>) (<a href="https://github.com/jparkerholder/ASEBO" target="_blank" rel="nofollow">Code</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/rbo.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Provably Robust Blackbox Optimization for Reinforcement Learning</b>  </br> 
                                Krzysztof Choromanski*, Aldo Pacchiano*, <b> Jack Parker-Holder*</b>, Yunhao Tang, Deepali Jain, Yuxiang Yang, Atil Iscen, Jasmine Hsu, Vikas Sindhwani</br> 
                                <i> The Conference on Robot Learning (CoRL), 2019 </i> <font color=#189441><strong>(Spotlight)</strong></font>  </br>
                                (<a href="https://arxiv.org/abs/1903.02993" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>                    
            </div>
            </div>

            <hr/>  


        <div class="row">
            <div class="col-sm-2">
                <h5>Workshop Papers</h5>
            </div>
            <div class="col-sm-10">    

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/vd4rl.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Challenges and Opportunities in Offline Reinforcement Learning from Visual Observations </b>  </br> 
                                Cong Lu, Philip J. Ball, Tim G. J. Rudner, <b>Jack Parker-Holder</b>, Michael A. Osborne, Yee Whye Teh </br> 
                                <i>L-DOD, RSS, 2022 </i> </i> <font color=#189441><strong>(Outstanding Paper Award)</strong></font> </br>
                                (<a href="https://arxiv.org/abs/2206.04779" target="_blank" rel="nofollow">ArXiv</a>) (<a href="https://github.com/conglu1997/v-d4rl" target="_blank" rel="nofollow">Code</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

            <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/samplr.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Grounding Aleatoric Uncertainty in Unsupervised Environment Design </b>  </br> 
                                Minqi Jiang, Michael Dennis, <b>Jack Parker-Holder</b>, Heinrich Küttler, Edward Grefenstette, Tim Rocktäschel, Jakob Foerster </br> 
                                <i>Deep RL Workshop, NeurIPS, 2021 </i> </br>
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/vplr.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Return Dispersion as an Estimator of Learning Potential for Prioritized Level Replay </b>  </br> 
                                Iryna Korshunova, Minqi Jiang, <b>Jack Parker-Holder</b>, Tim Rocktäschel, Edward Grefenstette  </br> 
                                <i>Deep RL Workshop, NeurIPS, 2021 </i> </br>
                                <i>I (Still) Can’t Believe It’s Not Better Workshop, NeurIPS, 2021 </i> </br>
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/sop.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Taming the Herd: Multi-Modal Meta-Learning with a Population of Agents </b>  </br> 
                                Robert Müller, <b> Jack Parker-Holder</b>, Aldo Pacchiano </br> 
                                <i> The Fourth Lifelong Machine Learning Workshop at ICML, 2020 </i>  </br>
                                (<a href="https://openreview.net/pdf?id=SLcfDWo-ztp" target="_blank" rel="nofollow">Paper</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/chromatic.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Reinforcement Learning with Chromatic Networks for Compact Architecture Search </b></br> 
                                Xingyou Song, Krzysztof Choromanski, <b>Jack Parker-Holder</b>, Yunhao Tang, Wenbo Gao, Aldo Pacchiano, Tamas Sarlos, Deepali Jain, Yuxiang Yang </br> 
                                <i>The ICLR Workshop on Neural Architecture Search, 2020 </i> </br>
                                (<a href="https://arxiv.org/abs/1907.06511" target="_blank" rel="nofollow">ArXiv</a>) 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>


            </div>
            </div>

            <hr/>    

        <div class="row">
            <div class="col-sm-2">
                <h5>Preprints</h5>
            </div>
            <div class="col-sm-10">    

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/iap.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Unlocking Pixels for Reinforcement Learning via Implicit Attention </b>  </br> 
                                Krzysztof Choromanski*, Deepali Jain*, <b> Jack Parker-Holder*</b>, Xingyou Song*, Valerii Likhosherstov, Anirban Santara, Aldo Pacchiano, Yunhao Tang, Adrian Weller </br> 
                                (<a href="https://arxiv.org/abs/2102.04353" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  
            </div>
            </div>

            <hr/>    


        <div class="row">
            <div class="col-sm-2">
                <h5>Employment</h5>
            </div>
            <div class="col-sm-10">
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/fair.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Facebook AI Research </b> - <i> Intern, FAIR Labs </i> - (2021) </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/aspect.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Aspect Capital </b> - <i> Intern, Machine Learning Research </i> - (2020) </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/jpmc.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> JPMorgan Chase </b> - <i> Vice President, Quantitative Research </i> - (2012-2019) </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>                                                                                          
            </div>
        </div>
        <hr/>

        <div class="row">
            <div class="col-sm-2">
                <h5>Education</h5>
            </div>
            <div class="col-sm-10">
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/oxford.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> University of Oxford </b> - <i> DPhil Machine Learning </i> - (2019-) </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 


                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/columbia.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Columbia University </b> - <i> MA QMSS </i> - (2016-2018)  </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>                                                                                          

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/exeter.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> University of Exeter </b> - <i> BSc Mathematics </i> - (2009-2012)  </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>                                                                                          
            </div> 

        </div>

        <hr/>

        <div class="row">
            <div class="col-sm-2">
                <h5>Additional Information</h5>
            </div>
            <div class="col-sm-10">
          

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-12 columns">
                                <ul>
                                <li><b>Reviewing</b> <i>AISTATS</i>: '21, <i>ICLR</i>: '21, '22 <font color=#189441><strong>(Highlighted Reviewer)</strong></font>, <i>ICML</i>: '21, <i>NeurIPS</i>: '21 <font color=#189441><strong>(Top 8%)</strong></font>, '22. 
                                </li>
                                </br> 
                                <li><b>Interests</b> In normal times I practice Brazilian Jiu Jitsu (blue belt from <a href="https://en.wikipedia.org/wiki/Ailson_Brites" target="_blank" rel="nofollow">Ailson Henrique Brites</a>). 
                                </li>
                                </br> 
                                </ul>
                            </div>
                        </td>
                    </tr>
                </table> 
   
            </div>
            </div>
        <hr/>


        <div class="footer">
	  <img  src="img/robot.png" alt="Robot" class="seal"></a>
            <a>jparkerholder@gmail.com </a> <span class="sep">|</span>
            <a href="http://github.com/jparkerholder">GitHub</a> <span class="sep">|</span>
            <a href="https://www.linkedin.com/in/jack-parker-holder-0bb66a29">LinkedIn</a>
	   <img src="img/robot.png" style="float: right" alt="NA" class="seal"></a>
        </div>
    </div>
</br></br>
</body>

</html>
