
<!DOCTYPE html>
<html lang="en">
  <head>	  
    <!-- Global Site Tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-107224691-1"></script>
    <script>
       window.dataLayer = window.dataLayer || [];
       function gtag(){dataLayer.push(arguments)};
       gtag('js', new Date());

       gtag('config', 'UA-107224691-1');
    </script>

    <title>Jack Parker-Holder</title>
	  
    <!-- Credit to Reid Pryzant from Stanford for the website design... I largely plagiarized his work! -->

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
    <script type="text/javascript" src="https://use.fontawesome.com/981e0eb420.js"></script>
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link href='https://fonts.googleapis.com/css?family=Lato:300,400,700,900%7COpen+Sans:400,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="./static/style.css" />

    <link rel="shortcut icon" href="./img/favicon.ico" >
</head>


<body>
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
    	      <img src="img/jack_headshot.jpeg" alt="JPH :)" class="headshot">
    	      <br/>
                    <h1>Jack Parker-Holder
                        <small>
                            <a>jack.parker-holder@spc.ox.ac.uk </a> <span class="sep">|</span>
                            <span style="display: inline-block; white-space: nowrap;">
                                <a href="http://github.com/jparkerholder"><i class="fa fa-git"></i></a> <span class="sep">|</span>
                                <a href="https://www.linkedin.com/in/jack-parker-holder-0bb66a29"><i class="fa fa-linkedin-square"></i></a>
                            </span>
                        </small>
                    </h1>
            </div>
        </div>
        <hr/>
        <div class="row">
            <div class="col-sm-2"><h5>About</h5></div>
            <div class="col-sm-10">
I am a third year DPhil student at St Peter's College, Oxford, where I am part of the <a href="http://www.robots.ox.ac.uk/~parg/" target="_blank" rel="nofollow">Machine Learning Research Group</a>, advised by <a href="https://www.robots.ox.ac.uk/~sjrob/" target="_blank" rel="nofollow">Stephen Roberts</a>.
</br></br>

I am interested in ways use reinforcement learning (RL) to train generally capable agents that can be effective in the real world. I believe this will be made possible with an open-ended learning process, where environments constantly constantly propose new challenges [<a href="https://arxiv.org/abs/2110.02439" target="_blank" rel="nofollow">1</a>, <a href="https://arxiv.org/abs/2203.01302" target="_blank" rel="nofollow">2</a>] and agents adapt their configurations to solve them [<a href="https://arxiv.org/abs/2002.02518" target="_blank" rel="nofollow">3</a>, <a href="https://arxiv.org/abs/2106.15883" target="_blank" rel="nofollow">4</a>, <a href="https://arxiv.org/abs/2102.03765" target="_blank" rel="nofollow">5</a>]. To make this process unbounded, I am excited by methods to actively encourage diversity [<a href="https://arxiv.org/abs/2011.06505" target="_blank" rel="nofollow">8</a>], while I believe we can eventually use world models to learn simulators purely from offline data [<a href="https://arxiv.org/abs/2104.05632" target="_blank" rel="nofollow">9</a>, <a href="https://arxiv.org/abs/2110.04135" target="_blank" rel="nofollow">10</a>]. 

</br></br>
I have been incredibly fortunate to spend summers interning at FAIR London with Tim Rocktäschel and Ed Grefenstette and Aspect Capital in the ML group. Before coming to Oxford I was a VP in the Quantitative Research team at JPM in New York. While in America I studied for a Master's part-time at Columbia where I discovered the joys of machine learning research! I am originally from the UK, and studied Maths at Exeter. 

</br></br>

        </div>
        </div>
        <hr/>

        <div class="row">
            <div class="col-sm-2">
                <h5>News</h5>
            </div>
            <div class="col-sm-10">
          

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-12 columns">
                                <ul>
                                <li><b>[9/2021] </b> Three papers accepted to NeurIPS 2021! I'm grateful to work with such great people :) 
                                </li>
                                </br> 
                                <li><b>[6/2021]</b> I am interning at Facebook AI Research with Tim Rocktäschel and Ed Grefenstette. 
                                </li>
                                </br> 
                                <li><b>[11/2020]</b> PB2 was included into Ray Tune! Check out the <a href="https://www.anyscale.com/blog/population-based-bandits" target="_blank" rel="nofollow">blog post</a>. 
                                </li>
                                </br> 
                                <li><b>[9/2020]</b> Three papers accepted to NeurIPS 2020. Thank you to my amazing collaborators!! 
                                </li>
                                </br>  
                                <li><b>[6/2020]</b> Three papers accepted to the main conference at ICML 2020.
                                </li>
                                </li>
                                </br>                                  
                                <li><b>[2/2020]</b> New work on model-based RL, <i> Ready Policy One</i>, was covered by VentureBeat (<a href="https://venturebeat.com/2020/02/11/researchers-develop-technique-to-increase-sample-efficiency-in-reinforcement-learning/" target="_blank" rel="nofollow">here</a>). </li>
                                </ul>
                            </div>
                        </td>
                    </tr>
                </table> 
   
            </div>
            </div>
        <hr/>

        <div class="row">
            <div class="col-sm-2">
                <h5>Conference Papers</h5>
            </div>
            <div class="col-sm-10">



                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/revisiting.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Revisiting Design Choices in Offline Model Based Reinforcement Learning  </b>  </br> 
                                Cong Lu*, Philip Ball*, <b>Jack Parker-Holder</b>, Michael Osborne, Stephen Roberts  </br> 
                                <i>International Conference on Learning Representations (ICLR), 2022 </i> <font color=#189441><strong>(Spotlight)</strong></font>  </br>
                                <i>Reinforcement Learning for Real Life Workshop @ ICML, 2021 </i> <font color=#189441><strong>(Spotlight)</strong></font>  </br>
                                (<a href="https://drive.google.com/file/d/1qQDeG-nQ5-XqARssY3X2YAAFwp8_n2Nq/view" target="_blank" rel="nofollow">Paper</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  


                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/texus.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Towards an Understanding of Default Policies in Multitask Policy Optimization </b>  </br> 
                                Ted Moskovitz, Michael Arbel, <b>Jack Parker-Holder</b>, Aldo Pacchiano</br> 
                                <i>Artificial Intelligence and Statistics (AISTATS), 2022 </i> <font color=#189441><strong>(Oral)</strong></font>  </br>
                                (<a href="https://arxiv.org/abs/2111.02994" target="_blank" rel="nofollow">Paper</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/osa.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>On-the-fly Strategy Adaptation for ad-hoc Agent Coordination  </b>  </br> 
                                Jaleh Zand, <b>Jack Parker-Holder</b>, Stephen Roberts  </br> 
                                <i>International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), 2022 </i> </br>
                                <i>Cooperative AI Workshop, NeurIPS, 2021 </i> </br>
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/grr.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Lyapunov Exponents for Diversity in Differentiable Games</b>  </br> 
                                Jonathan Lorraine, Paul Vicol, <b>Jack Parker-Holder</b>, Tal Kachman, Luke Metz, Jakob Foerster </br> 
                                <i>International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), 2022 </i> </br>
                                <i>Beyond first-order methods in ML systems workshop, ICML, 2021 </i> </br>
                                (<a href="https://arxiv.org/abs/2112.14570" target="_blank" rel="nofollow">Paper</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/unclear.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Same State, Different Task: Continual Reinforcement Learning without Interference </b>  </br> 
                                Samuel Kessler, <b> Jack Parker-Holder</b>, Philip Ball, Stefan Zohren, Stephen Roberts </br> 
                                <i>AAAI Conference on Artificial Intelligence, 2022 </i>  </br>
                                <i>Workshop on Continual Learning, ICML, 2020 </i>  </br>
                                (<a href="https://arxiv.org/abs/2106.02940" target="_blank" rel="nofollow">Paper</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/pb2m.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Tuning Mixed Input Hyperparameters on the Fly for Efficient Population Based AutoRL </b>  </br> 
                                 <b>Jack Parker-Holder</b>, Vu Nguyen, Shaan Desai, Stephen Roberts </br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2021 </i>  </br>                                  
                                (<a href="https://arxiv.org/abs/2106.15883" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/silverstone.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Replay-Guided Adversarial Environment Design </b>  </br> 
                                 Minqi Jiang*, Michael Dennis*, <b>Jack Parker-Holder</b>, Jakob Foerster, Edward Grefenstette, Tim Rocktäschel </br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2021 </i>  </br>     
                                (<a href="https://arxiv.org/abs/2110.02439" target="_blank" rel="nofollow">ArXiv</a>)                             
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/dope.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Tactical Optimism and Pessimism for Deep Reinforcement Learning  </b>  </br> 
                                Ted Moskovitz, <b> Jack Parker-Holder</b>, Aldo Pacchiano, Michael Arbel, Michael I. Jordan </br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2021 </i>  </br> 
                                (<a href="https://arxiv.org/abs/2102.03765" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 


                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/minihack.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> MiniHack the Planet: A Sandbox for Open-Ended Reinforcement Learning Research </b>  </br> 
                                Mikayel Samvelyan, Robert Kirk, Vitaly Kurin, <b> Jack Parker-Holder</b>, Minqi Jiang, Eric Hambro, Fabio Petroni, Heinrich Kuttler, Edward Grefenstette, Tim Rocktäschel  </br> 
                                <i>NeurIPS (Datasets and Benchmarks Track), 2021 </i> </br>
                                (<a href="https://openreview.net/forum?id=skFwlyefkWJ" target="_blank" rel="nofollow">Paper</a>)
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/AugWM.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environment </b>  </br> 
                                Philip J Ball*, Cong Lu*, <b> Jack Parker-Holder</b>, Stephen Roberts </br> 
                                <i>The International Conference on Machine Learning (ICML), 2021 </i> </br>
                                <i>Workshop on Self-Supervision in Reinforcement Learning, ICLR, 2021 </i>  <font color=#189441><strong>(Spotlight)</strong></font>  </br>
                                (<a href="https://arxiv.org/pdf/2104.05632.pdf" target="_blank" rel="nofollow">Paper</a>) (<a href="https://sites.google.com/view/augmentedworldmodels/" target="_blank" rel="nofollow">Website</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/narl.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Towards Tractable Optimism in Model-Based Reinforcement Learning </b>  </br> 
                                Aldo Pacchiano*, Philip Ball*, <b> Jack Parker-Holder*</b>, Krzysztof Choromanski, Stephen Roberts </br> 
                                 <i> Uncertainty in Artificial Intelligence (UAI), 2021 </i> </br>
                               (<a href="https://arxiv.org/abs/2006.11911" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/dvd.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Effective Diversity in Population-Based Reinforcement Learning </b>  </br> 
                                <b> Jack Parker-Holder*</b>, Aldo Pacchiano*, Krzysztof Choromanski, Stephen Roberts </br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2020 </i> <font color=#189441><strong>(Spotlight)</strong></font> </br> 
                                <i> The Fourth Lifelong Machine Learning Workshop at ICML, 2020 </i> </br>
                                (<a href="https://arxiv.org/abs/2002.00632" target="_blank" rel="nofollow">ArXiv</a>) (<a href="https://www.youtube.com/watch?v=2k26xxPw3CA" target="_blank" rel="nofollow">Talk</a>) (<a href="https://github.com/jparkerholder/DvD_ES" target="_blank" rel="nofollow">Code</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/p2bt.png" width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Provably Efficient Online Hyperparameter Optimization with Population-Based Bandits </b>  </br> 
                                <b>Jack Parker-Holder</b>, Vu Nguyen, Stephen Roberts </br>                                 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2020 </i>  </br> 
                                <i>The 7th ICML Workshop on Automated Machine Learning (AutoML), 2020  </i> <font color=#189441><strong>(Contributed Talk)</strong></font> </br>
                                (<a href="https://arxiv.org/abs/2002.02518" target="_blank" rel="nofollow">ArXiv</a>) (<a href="https://www.anyscale.com/blog/population-based-bandits" target="_blank" rel="nofollow">Blog</a>) (<a href="https://github.com/jparkerholder/PB2" target="_blank" rel="nofollow">Code</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                <img src="img/pubs/rr.png" width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Ridge Rider: Finding diverse solutions by following eigenvectors of the Hessian </b>  </br> 
                                <b>Jack Parker-Holder*</b>, Luke Metz, Cinjon Resnick, Hengyuan Hu, Adam Lerer, Alistair HP Letcher, Alex Peysakhovich, Aldo Pacchiano, Jakob Foerster* </br>                                 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2020 </i>  </br> 
                                <i>Beyond First Order Methods in ML Systems, ICML, 2020 </i> <font color=#189441><strong>(Spotlight)</strong></font> </br>
                                (<a href="https://arxiv.org/abs/2011.06505?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%253A+arxiv%252FQSXk+%2528ExcitingAds%2521+cs+updates+on+arXiv.org%2529" target="_blank" rel="nofollow">Arxiv</a>) (<a href="https://bair.berkeley.edu/blog/2020/11/13/ridge-rider/" target="_blank" rel="nofollow">Blog</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/rp1.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Ready Policy One: World Building Through Active Learning </b>  </br> 
                                Philip Ball*, <b> Jack Parker-Holder*</b>, Aldo Pacchiano, Krzysztof Choromanski, Stephen Roberts </br> 
                                <i>The International Conference on Machine Learning (ICML), 2020 </i>  </br> 
                                (<a href="https://arxiv.org/pdf/2002.02693" target="_blank" rel="nofollow">ArXiv</a>) (<a href="https://venturebeat.com/2020/02/11/researchers-develop-technique-to-increase-sample-efficiency-in-reinforcement-learning/" target="_blank" rel="nofollow">Media</a>) (<a href="https://github.com/fiorenza2/ReadyPolicyOne" target="_blank" rel="nofollow">Code</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/wass.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Learning to Score Behaviors for Guided Policy Optimization</b>  </br> 
                                Aldo Pacchiano*, <b> Jack Parker-Holder*</b>, Yunhao Tang*, Anna Choromanska, Krzysztof Choromanski, Michael I. Jordan </br> 
                                <i>The International Conference on Machine Learning (ICML), 2020 </i> </br>
                                (<a href="https://arxiv.org/abs/1906.04349" target="_blank" rel="nofollow">ArXiv</a>) (<a href="https://github.com/behaviorguidedRL/BGRL" target="_blank" rel="nofollow">Code</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/ortho.png" width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Stochastic Flows and Geometric Optimization on the Orthogonal Group</b>  </br> 
                                Krzysztof Choromanski*, David Cheikhi*, Jared Davis*, Valerii Likhosherstov*, Achille Nazaret*, Achraf Bahamou*, Xingyou Song*, Mrugank Akarte, <b> Jack Parker-Holder</b>, Jacob Bergquist, Yuan Gao, Aldo Pacchiano, Tamas Sarlos, Adrian Weller, Vikas Sindhwani </br> 
                                <i>The International Conference on Machine Learning (ICML), 2020 </i> </br>
                                (<a href="https://arxiv.org/abs/2003.13563" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 


                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/dppmc.png" width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> </br> Practical Nonisotropic Monte Carlo Sampling in High Dimensions via Determinantal Point Processes </b></br>
                                Krzysztof Choromanski*, Aldo Pacchiano*, <b> Jack Parker-Holder*</b>, Yunhao Tang* </br> 
                                <i>Artificial Intelligence and Statistics (AISTATS), 2020 </i> </br>
                                (<a href="https://arxiv.org/abs/1905.12667" target="_blank" rel="nofollow">ArXiv</a>) 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  	      

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/asebo.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>From Complexity to Simplicity: Adaptive ES-Active Subspaces for Blackbox Optimization</b></br> 
                                Krzysztof Choromanski*, Aldo Pacchiano*, <b> Jack Parker-Holder*</b>, Yunhao Tang*, Vikas Sindhwani</br> 
                                <i>Advances in Neural Information Processing Systems (NeurIPS), 2019  </i> </br>
                                (<a href="https://arxiv.org/pdf/1903.04268" target="_blank" rel="nofollow">ArXiv</a>) (<a href="https://github.com/jparkerholder/ASEBO" target="_blank" rel="nofollow">Code</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/rbo.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Provably Robust Blackbox Optimization for Reinforcement Learning</b>  </br> 
                                Krzysztof Choromanski*, Aldo Pacchiano*, <b> Jack Parker-Holder*</b>, Yunhao Tang, Deepali Jain, Yuxiang Yang, Atil Iscen, Jasmine Hsu, Vikas Sindhwani</br> 
                                <i> The Conference on Robot Learning (CoRL), 2019 </i> <font color=#189441><strong>(Spotlight)</strong></font>  </br>
                                (<a href="https://arxiv.org/abs/1903.02993" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>                    
            </div>
            </div>

            <hr/>  


        <div class="row">
            <div class="col-sm-2">
                <h5>Workshop Papers</h5>
            </div>
            <div class="col-sm-10">    

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/accel.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>That Escalated Quickly: Compounding Complexity by Editing Levels at the Frontier of Agent Capabilities </b>  </br> 
                                <b>Jack Parker-Holder</b>, Minqi Jiang, Michael Dennis, Mikayel Samvelyan, Jakob Foerster, Edward Grefenstette, Tim Rocktäschel </br> 
                                <i>Deep RL Workshop, NeurIPS, 2021 </i> </br>
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/samplr.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Grounding Aleatoric Uncertainty in Unsupervised Environment Design </b>  </br> 
                                Minqi Jiang, Michael Dennis, <b>Jack Parker-Holder</b>, Heinrich Küttler, Edward Grefenstette, Tim Rocktäschel, Jakob Foerster </br> 
                                <i>Deep RL Workshop, NeurIPS, 2021 </i> </br>
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/vplr.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Return Dispersion as an Estimator of Learning Potential for Prioritized Level Replay </b>  </br> 
                                Iryna Korshunova, Minqi Jiang, <b>Jack Parker-Holder</b>, Tim Rocktäschel, Edward Grefenstette  </br> 
                                <i>Deep RL Workshop, NeurIPS, 2021 </i> </br>
                                <i>I (Still) Can’t Believe It’s Not Better Workshop, NeurIPS, 2021 </i> </br>
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/sop.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Taming the Herd: Multi-Modal Meta-Learning with a Population of Agents </b>  </br> 
                                Robert Müller, <b> Jack Parker-Holder</b>, Aldo Pacchiano </br> 
                                <i> The Fourth Lifelong Machine Learning Workshop at ICML, 2020 </i>  </br>
                                (<a href="https://openreview.net/pdf?id=SLcfDWo-ztp" target="_blank" rel="nofollow">Paper</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/chromatic.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Reinforcement Learning with Chromatic Networks for Compact Architecture Search </b></br> 
                                Xingyou Song, Krzysztof Choromanski, <b>Jack Parker-Holder</b>, Yunhao Tang, Wenbo Gao, Aldo Pacchiano, Tamas Sarlos, Deepali Jain, Yuxiang Yang </br> 
                                <i>The ICLR Workshop on Neural Architecture Search, 2020 </i> </br>
                                (<a href="https://arxiv.org/abs/1907.06511" target="_blank" rel="nofollow">ArXiv</a>) 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>


            </div>
            </div>

            <hr/>    

        <div class="row">
            <div class="col-sm-2">
                <h5>Preprints</h5>
            </div>
            <div class="col-sm-10">    

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/iap.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>Unlocking Pixels for Reinforcement Learning via Implicit Attention </b>  </br> 
                                Krzysztof Choromanski*, Deepali Jain*, <b> Jack Parker-Holder*</b>, Xingyou Song*, Valerii Likhosherstov, Anirban Santara, Aldo Pacchiano, Yunhao Tang, Adrian Weller </br> 
                                (<a href="https://arxiv.org/abs/2102.04353" target="_blank" rel="nofollow">ArXiv</a>)
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  
            </div>
            </div>

            <hr/>    


        <div class="row">
            <div class="col-sm-2">
                <h5>Employment</h5>
            </div>
            <div class="col-sm-10">
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/fair.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Facebook AI Research </b> - <i> Intern, FAIR Labs </i> - (2021) </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/aspect.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Aspect Capital </b> - <i> Intern, Machine Learning Research </i> - (2020) </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/jpmc.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> JPMorgan Chase </b> - <i> Vice President, Quantitative Research </i> - (2012-2019) </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>                                                                                          
            </div>
        </div>
        <hr/>

        <div class="row">
            <div class="col-sm-2">
                <h5>Education</h5>
            </div>
            <div class="col-sm-10">
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/oxford.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> University of Oxford </b> - <i> DPhil Machine Learning </i> - (2019-) </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 


                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/columbia.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Columbia University </b> - <i> MA QMSS </i> - (2016-2018)  </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>                                                                                          

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/exeter.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> University of Exeter </b> - <i> BSc Mathematics </i> - (2009-2012)  </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>                                                                                          
            </div> 

        </div>

        <hr/>

        <div class="row">
            <div class="col-sm-2">
                <h5>Additional Information</h5>
            </div>
            <div class="col-sm-10">
          

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-12 columns">
                                <ul>
                                <li><b>Reviewing</b> <i>AISTATS</i>: '21, <i>ICLR</i>: '21, '22, <i>ICML</i>: '21, <i>NeurIPS</i>: '21 <font color=#189441><strong>(Top 8%)</strong></font>. 
                                </li>
                                </br> 
                                <li><b>Interests</b> In normal times I practice Brazilian Jiu Jitsu (blue belt from <a href="https://en.wikipedia.org/wiki/Ailson_Brites" target="_blank" rel="nofollow">Ailson Henrique Brites</a>). 
                                </li>
                                </br> 
                                </ul>
                            </div>
                        </td>
                    </tr>
                </table> 
   
            </div>
            </div>
        <hr/>


        <div class="footer">
	  <img  src="img/robot.png" alt="Robot" class="seal"></a>
            <a>jackph@robots.ox.ac.uk </a> <span class="sep">|</span>
            <a href="http://github.com/jparkerholder">GitHub</a> <span class="sep">|</span>
            <a href="https://www.linkedin.com/in/jack-parker-holder-0bb66a29">LinkedIn</a>
	   <img src="img/robot.png" style="float: right" alt="NA" class="seal"></a>
        </div>
    </div>
</br></br>
</body>

</html>
